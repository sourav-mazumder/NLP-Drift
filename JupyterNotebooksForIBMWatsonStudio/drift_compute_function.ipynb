{"cells": [{"metadata": {"id": "622abb2eebac41f087e36a6234443714"}, "cell_type": "code", "source": "#setting up training data reader function in cae you are using this notebook in your local machine/laptop\n\n# import pandas as pd\n# training_data_drift_stats = pd.read_csv(<'file name with path'>)", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Click the 'Find and Add Data' (0100) icon in Notebook toolbar. \n# Click on 'training_data_drift_statistics.csv' file and select 'pandas data frame' from drop down\n# In cae you are using this notebook in your local environment then you can directly read the data from the csv file using Pandas\"", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "training_data_drift_stats = df_data_1", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!pip install -U sentence-transformers", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "Collecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 85 kB 3.8 MB/s eta 0:00:011\n\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 5.5 MB 40.7 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from sentence-transformers) (4.62.3)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from sentence-transformers) (1.10.2)\nRequirement already satisfied: torchvision in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from sentence-transformers) (0.11.3)\nRequirement already satisfied: numpy in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from sentence-transformers) (1.20.3)\nRequirement already satisfied: scikit-learn in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from sentence-transformers) (1.0.2)\nRequirement already satisfied: scipy in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from sentence-transformers) (1.7.3)\nCollecting nltk\n  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.5 MB 64.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: sentencepiece in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from sentence-transformers) (0.1.96)\nCollecting huggingface-hub>=0.4.0\n  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 163 kB 68.7 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.26.0)\nCollecting filelock\n  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.4.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.11.2)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n  Downloading tokenizers-0.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7.6 MB 25.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: joblib in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from nltk->sentence-transformers) (0.17.0)\nRequirement already satisfied: click in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.7)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\nRequirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from torchvision->sentence-transformers) (9.0.1)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=eb14403f5d07622744eee1ca75a2b9192968589853120cbbccd611b3e4804363\n  Stored in directory: /tmp/wsuser/.cache/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\nSuccessfully built sentence-transformers\nInstalling collected packages: filelock, tokenizers, huggingface-hub, transformers, nltk, sentence-transformers\nSuccessfully installed filelock-3.8.0 huggingface-hub-0.10.1 nltk-3.7 sentence-transformers-2.2.2 tokenizers-0.13.1 transformers-4.24.0\n", "name": "stdout"}]}, {"metadata": {"id": "b1d26427199c4e72b18d834d0d5c36d7"}, "cell_type": "code", "source": "#setting up mean pooling function for tokenizer\n\ndef mean_pooling(model_output, attention_mask):\n    \n    import torch \n    \n    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    \n    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)", "execution_count": 4, "outputs": []}, {"metadata": {"id": "e024f792-906d-41db-ae39-96cedae32507"}, "cell_type": "code", "source": "#setting up drift computation function\n\ndef compute_drift(data):\n    import os\n    import numpy as np\n    import torch \n    import torch.nn.functional as F\n    from transformers import AutoTokenizer, AutoModel \n    from sentence_transformers import SentenceTransformer\n    from scipy.stats import wasserstein_distance\n\n        #getting training data\n        \n    train_bins = training_data_drift_stats['train_bins']\n    train_vals = training_data_drift_stats['train_vals']\n    \n        #getting payload data\n        \n    payload_data = data.get(\"input_data\")[0].get(\"values\")[1]\n\n\n        #transforming payload data\n                    \n    tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n    model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n\n    encoded_input = tokenizer(payload_data, padding=True, truncation=True, return_tensors='pt')\n\n    with torch.no_grad():\n        model_output = model(**encoded_input)\n\n    sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n\n    sentence_embeddings = F.normalize(sentence_embeddings, p = 2, dim = 1)\n    sentence_embeddings = sentence_embeddings.detach().numpy().flatten()\n\n    sentence_embeddings_hist = np.histogram(sentence_embeddings, density = True)\n    scoring_vals = sentence_embeddings_hist[0].tolist()\n    scoring_bins = sentence_embeddings_hist[1].tolist()[:-1]\n\n        #calculating drift using wasserstein_distance\n        \n    drift = str(round(wasserstein_distance(u_values = train_bins, v_values = scoring_bins,\n                               u_weights = train_vals, v_weights = scoring_vals),4))\n        \n    return drift                                                                                                     ", "execution_count": 14, "outputs": []}, {"metadata": {"id": "d8ec6fee-cc8e-405b-948b-3264eaa4af86"}, "cell_type": "code", "source": "# defining payload data for local testing\n\npayload_data = {\n  \"input_data\": [\n    {\n      \"fields\": [\"stars\",\"text\"],\n      \"values\": [[\"1.0\",\"4.0\",\"3.0\"],[\"it was fun\",\"it was bad\",\"it was okay\"]]\n    }\n  ]\n}", "execution_count": 15, "outputs": []}, {"metadata": {"id": "d6bce0ef-86ee-4750-908b-1e255c354ca1"}, "cell_type": "code", "source": "#computing drift\n\ncompute_drift(payload_data)", "execution_count": 16, "outputs": [{"output_type": "display_data", "data": {"text/plain": "Downloading:   0%|          | 0.00/352 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "853d56533c0e4b7d9b7165cc56445937"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "14951ea60e6d42409b817165bc7072c1"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "3e30aed523bd4d499b96fe36366ff951"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "ebafa6c749af443da7cd2d759bbf28d5"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading:   0%|          | 0.00/573 [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "de70560d93b641dcb1f4cdec9d1f5ff1"}}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Downloading:   0%|          | 0.00/134M [00:00<?, ?B/s]", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "1bbfc44872244d80b45fbe462db81c0b"}}, "metadata": {}}, {"output_type": "execute_result", "execution_count": 16, "data": {"text/plain": "'0.0166'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}