{"cells": [{"metadata": {}, "cell_type": "code", "source": "#Create Peoject object by using project id and project token. \n#Click on 'More' (Triple dots) icon in Notebook toolbar. Then click 'Insert Project Token' to generate the necessary code here.", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Click the 'Find and Add Data' (0100) icon in Notebook toolbar. \n#Click on 'source_sentences_shaped.csv' file and select 'pandas data frame' from drop down\n# In cae you are using this notebook in your local environment then you can directly read the data from the csv file using Pandas\"", "execution_count": null, "outputs": []}, {"metadata": {"id": "57ff0466021943a98a1c4f127ecc795c"}, "cell_type": "code", "source": "source_sentences = list(df_data_1['text'])\nlen(source_sentences)", "execution_count": null, "outputs": []}, {"metadata": {"id": "39ddfff291a44766b7b67d37b10255ec"}, "cell_type": "code", "source": "!pip install -U sentence-transformers", "execution_count": null, "outputs": []}, {"metadata": {"id": "6c3f39f6-d86f-48c9-a019-b72d23bc6c1c"}, "cell_type": "code", "source": "from transformers import AutoTokenizer, AutoModel \nimport torch \nimport torch.nn.functional as F\nimport numpy as anp\nfrom sentence_transformers import SentenceTransformer", "execution_count": null, "outputs": []}, {"metadata": {"id": "b1af2fdb4dcb4bf980db21487937841a"}, "cell_type": "code", "source": "def mean_pooling(model_output, attention_mask):\n    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)", "execution_count": null, "outputs": []}, {"metadata": {"id": "a15231df48194f2eb797c9713e775fd7"}, "cell_type": "code", "source": "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\nmodel = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')", "execution_count": null, "outputs": []}, {"metadata": {"id": "5fd2b94a8a4645be8088acf809998a4e"}, "cell_type": "code", "source": "# encoding the source sentences\nencoded_input = tokenizer(source_sentences, padding=True, truncation=True, return_tensors='pt')", "execution_count": null, "outputs": []}, {"metadata": {"id": "0f746754fdaa400c838a4fb7f5455125"}, "cell_type": "code", "source": "# computing the embeddings\nwith torch.no_grad():\n    embedding_model = model(**encoded_input)\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "4dea5127610740a8b46ed86b4922a1ed"}, "cell_type": "code", "source": "# Perform pooling \nsentence_embeddings = mean_pooling(embedding_model, encoded_input['attention_mask'])\n # Normalise embeddings \nsentence_embeddings = F.normalize(sentence_embeddings, p = 2, dim = 1)\nsentence_embeddings = sentence_embeddings.detach().numpy().flatten()\nprint(\"Embeddings shape: {}\".format(sentence_embeddings.shape))", "execution_count": null, "outputs": []}, {"metadata": {"id": "11380093c4f1422082d94891d51794ed"}, "cell_type": "code", "source": "import numpy as np\nsentence_embeddings_hist = np.histogram(sentence_embeddings, density = True)\ntrain_embeddings_vals = sentence_embeddings_hist[0].tolist()\ntrain_embeddings_bins = sentence_embeddings_hist[1].tolist()[:-1]\ntrain_embeddings = {'train_vals': train_embeddings_vals, 'train_bins': train_embeddings_bins}", "execution_count": null, "outputs": []}, {"metadata": {"id": "6519344d779d4094a4771988fa13744c"}, "cell_type": "code", "source": "import pandas as pd\nembeddings_df = pd.DataFrame(train_embeddings)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "project.save_data(\"training_data_drift_stats.csv\", embeddings_df.to_csv(index=False))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#In case you are uing this notebook in your local machine/laptop use following code to save the file\"\n#embeddings_df.to_csv('train_data_drift_stats.csv', index=False, mode='w+')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}